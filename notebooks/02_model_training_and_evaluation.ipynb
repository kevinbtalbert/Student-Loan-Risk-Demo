{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Student Loan Risk Demo - Model Training and Evaluation\n",
        "\n",
        "This notebook demonstrates the complete machine learning pipeline for predicting student loan delinquency risk.\n",
        "\n",
        "**Project Overview:**\n",
        "- **Client:** Maximus (Student Loan Processing Company)\n",
        "- **Partner:** FiServ (Follow-up with at-risk students)\n",
        "- **Objective:** Train and evaluate ML models for delinquency prediction\n",
        "- **Platform:** Cloudera Machine Learning\n",
        "\n",
        "## üìã Notebook Contents\n",
        "\n",
        "1. **Data Loading and Preprocessing**\n",
        "2. **Feature Engineering Pipeline**\n",
        "3. **Model Training (Multiple Algorithms)**\n",
        "4. **Model Evaluation and Comparison**\n",
        "5. **Feature Importance Analysis**\n",
        "6. **Model Selection and Validation**\n",
        "7. **Performance Metrics and Visualization**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "import sys\n",
        "import os\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import joblib\n",
        "\n",
        "# Add utils to path\n",
        "sys.path.append('../utils')\n",
        "\n",
        "# Import custom modules\n",
        "from data_preprocessing import StudentLoanPreprocessor\n",
        "from ml_models import StudentLoanRiskModels\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Environment setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Prepare Data\n",
        "\n",
        "First, let's load the synthetic student loan dataset and prepare it for machine learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the synthetic dataset\n",
        "data_path = '../data/synthetic/student_loan_master_dataset.csv'\n",
        "\n",
        "if os.path.exists(data_path):\n",
        "    df = pd.read_csv(data_path)\n",
        "    print(f\"Dataset loaded successfully!\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"Delinquency rate: {df['is_delinquent'].mean():.1%}\")\n",
        "    display(df.head())\n",
        "else:\n",
        "    print(f\"Dataset not found at {data_path}\")\n",
        "    print(\"Please run the data generation notebook first or execute:\")\n",
        "    print(\"python main.py --generate-data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preprocessing and Feature Engineering\n",
        "\n",
        "Now let's preprocess the data and engineer features for machine learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the preprocessor and prepare training data\n",
        "if 'df' in locals():\n",
        "    print(\"Initializing data preprocessing...\")\n",
        "    \n",
        "    # Create preprocessor instance\n",
        "    preprocessor = StudentLoanPreprocessor()\n",
        "    \n",
        "    # Prepare training and testing datasets\n",
        "    X_train, X_test, y_train, y_test = preprocessor.prepare_training_data(df, test_size=0.2, random_state=42)\n",
        "    \n",
        "    print(f\"‚úÖ Data preprocessing completed!\")\n",
        "    print(f\"Training set: {X_train.shape}\")\n",
        "    print(f\"Testing set: {X_test.shape}\")\n",
        "    print(f\"Target distribution - Train: {y_train.mean():.3f}, Test: {y_test.mean():.3f}\")\n",
        "    \n",
        "    # Display feature names\n",
        "    print(f\"\\nNumber of features: {len(preprocessor.get_feature_importance_names())}\")\n",
        "    print(\"Sample features:\", preprocessor.get_feature_importance_names()[:10])\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Please load the dataset first by running the previous cell.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train Multiple ML Models\n",
        "\n",
        "Let's train and compare multiple machine learning algorithms for delinquency prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train multiple ML models\n",
        "if 'X_train' in locals():\n",
        "    print(\"üöÄ Starting model training...\")\n",
        "    \n",
        "    # Initialize ML models\n",
        "    ml_models = StudentLoanRiskModels(random_state=42)\n",
        "    \n",
        "    # Train all models with hyperparameter tuning\n",
        "    results = ml_models.train_all_models(X_train, y_train, X_test, y_test)\n",
        "    \n",
        "    print(\"\\nüìä Model Performance Summary:\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    # Display results for each model\n",
        "    for model_name, model_results in results.items():\n",
        "        print(f\"\\n{model_name.replace('_', ' ').title()}:\")\n",
        "        print(f\"  AUC Score: {model_results['test_auc']:.4f}\")\n",
        "        print(f\"  Precision: {model_results['test_precision']:.4f}\")\n",
        "        print(f\"  Recall: {model_results['test_recall']:.4f}\")\n",
        "        print(f\"  F1-Score: {model_results['test_f1']:.4f}\")\n",
        "    \n",
        "    print(f\"\\nüèÜ Best model: {ml_models.best_model_name}\")\n",
        "    print(f\"üéØ Best AUC score: {ml_models.model_scores[ml_models.best_model_name]['test_auc']:.4f}\")\n",
        "    \n",
        "    # Save models\n",
        "    os.makedirs('../models', exist_ok=True)\n",
        "    ml_models.save_models('../models')\n",
        "    print(f\"\\nüíæ Models saved to ../models/\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Please run the data preprocessing step first.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
